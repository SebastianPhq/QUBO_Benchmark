#!/usr/bin/env python3
import os
import pandas as pd

# Define q values (as strings, consistent with the shell script)
q_values = ["0", "0.000001", "0.00001", "0.00005", "0.0001", "0.0005", "0.001", "0.01"]

# Define asset numbers and their corresponding time intervals
asset_numbers = [200, 499]
t_values = {200: 10, 499: 15}

# Set directory paths (corresponding to those generated by the shell script)
mst_prefix = './mst_files/'              # Directory where qoqo-generated .mst files are stored
lp_files_dir = './lp_files/'             # Directory where ZIMPL-generated .lp and .tbl files are stored
sol_input_prefix = './bqp_solutions/'    # Directory for BQP solution (.sol) files (original solutions used for matching)
sol_output_prefix = './qoqo_solutions/'   # Directory for the converted qoqo solution (.sol) files

def custom_read_tbl(file):
    """
    Reads a .tbl file, filters out the rows that meet the criteria,
    and processes the fourth column by extracting the part after '@'.
    """
    valid_rows = []
    with open(file, 'r') as f:
        for line in f:
            columns = line.strip().split()
            if len(columns) == 5 and columns[1] == 'v':
                # Extract the part after '@' in the fourth column
                columns[3] = columns[3].split('@')[-1]
                valid_rows.append(columns)
    return pd.DataFrame(valid_rows, columns=['col1', 'col2', 'col3', 'col4', 'col5'])

def read_sol_file(file):
    """
    Reads a .sol file, skipping comment lines,
    and processes the first column by extracting the part after '@'.
    """
    valid_rows = []
    with open(file, 'r') as f:
        for line in f:
            if not line.startswith('#'):
                columns = line.strip().split()
                if len(columns) == 2:
                    columns.append(columns[0].split('@')[-1])
                    valid_rows.append(columns)
    return pd.DataFrame(valid_rows, columns=['col1', 'col2', 'col3'])

def process_files():
    for a in asset_numbers:
        t_val = t_values[a]
        a_padded = f"{a:03d}"
        t_padded = f"{t_val:02d}"
        for q in q_values:
            # Use q directly (no additional formatting needed)
            q_str = q

            # Construct the MST file path (qoqo solution result)
            mst_file = os.path.join(mst_prefix, f"uqo_a{a_padded}_t{t_padded}_q{q_str}.mst")
            if not os.path.exists(mst_file):
                print(f"Warning: MST file {mst_file} does not exist. Skipping.")
                continue
            try:
                mst_df = pd.read_csv(mst_file, sep=r'\s+', header=None, names=['index', 'value'])
            except Exception as e:
                print(f"Error reading {mst_file}: {e}")
                continue
            # Process the 'index' column: extract the number after '#' and subtract 1
            mst_df['index'] = mst_df['index'].astype(str).str.split('#').str[1].astype(int) - 1

            # Construct the .tbl file path (generated by ZIMPL, same base name as the LP file but with .tbl extension)
            tbl_file = os.path.join(lp_files_dir, f"bqp_a{a_padded}_t{t_padded}_q{q_str}.tbl")
            if not os.path.exists(tbl_file):
                print(f"Warning: TBL file {tbl_file} does not exist. Skipping.")
                continue
            tbl_df = custom_read_tbl(tbl_file)
            tbl_df['col3'] = tbl_df['col3'].astype(int)

            # Merge mst_df and tbl_df based on tbl_df's 'col3' and mst_df's 'index'
            merged_df = pd.merge(tbl_df, mst_df, left_on='col3', right_on='index', how='inner')
            if merged_df.empty:
                print(f"Warning: No merged data for MST {mst_file} and TBL {tbl_file}.")
                continue
            # Extract the fourth column from tbl_df and the 'value' column from mst_df
            result_df = merged_df[['col4', 'value']]

            # Construct the original BQP solution file path (used as a matching reference)
            # File name format: bqp_a{a_padded}_t{t_padded}_q{q_str}.sol
            sol_file = os.path.join(sol_input_prefix, f"bqp_a{a_padded}_t{t_padded}_q{q_str}.sol")
            if not os.path.exists(sol_file):
                print(f"Warning: SOL file {sol_file} does not exist. Skipping.")
                continue
            sol_df = read_sol_file(sol_file)
            sol_df['col3'] = sol_df['col3'].astype(str)
            result_df['col4'] = result_df['col4'].astype(str)

            # Merge based on the matching identifiers to generate the final result (variable names and new values)
            final_merged_df = pd.merge(sol_df, result_df, left_on='col3', right_on='col4', how='inner')
            if final_merged_df.empty:
                print(f"Warning: No merge result for a={a}, t={t_val}, q={q_str}.")
                continue
            final_result_df = final_merged_df[['col1', 'value']]

            # Save the converted SOL file.
            # File name format: uqo_a{a_padded}_t{t_padded}_q{q_str}.sol, stored in the qoqo_solutions directory
            output_file = os.path.join(sol_output_prefix, f"uqo_a{a_padded}_t{t_padded}_q{q_str}.sol")
            final_result_df.to_csv(output_file, index=False, header=False, sep=' ', float_format='%.10f')
            print(f"Generated solution file: {output_file}")

if __name__ == '__main__':
    process_files()